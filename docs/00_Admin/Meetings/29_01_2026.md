### Team meeting

### Agenda
[[Guide for creating ontology (paper)]]
We need example questions / tasks for our chatbot!!!
We need to define limits of our domain
Can ontology be modified in the future?
We need to understand what data might be relevant to our potential user => we need to know our potential user

We need to provide comments to help LLM/RAG capture meaning of RDF concepts - basically its their conclusion [[Summary#Industry 4.0 Chatbot (2024)]]


Do we need some interface to record questions dataset? Also classify intent?
**Training detector is not feasible!** [[Summary#E-learning Chatbot (2021)]]


If we doing NLP stuff, our ontology should include synonyms and NL information [[Guide for creating ontology (paper)]]

Looks like we need to reverse engineer our ontology so we can understand what Tina wants from us
(if she will not give us proper info)

- use SPARQL +RDF & OWL or Cypher + Neo4j?
	- What tool captures our data structure the best?

Tasks:
- create UI for chatbot 
- create a tool which will autosend messages, record answers, assess them (somehow)
- create a google form to collect a dataset of chatbot questions (predefine categories? Who will assign it)
- We need research questions and fast!


Discussed tasks:
Additional meeting - where?
- Limit scope 
- define tasks
---
Rejected microservice architecture: too complex

---
E.g. Rule Based approach 
- look up in dictionary 1200 presets question - not feasible [text-to-graphql model conclusion]
- encode-decoder pipeline proposed:
	- llm pretraining with templates of questions (not feasible)

---
how llms work with graphs:
- describe graph as text - graph encoder function - how to encode?
	- llm prompt must be replaced to be in the same context (described in the same language) as graph description
	- They represent graph relations as some human concept (friendship, social network (node=person; rel=child, parent, a friend))
- prompt question:
Graph is big - we have to limit it first - how - get context?

NL convert into SPARQL iteratively: (another approach) - looks nice
![[Pasted image 20260129210915.png|450]]
Isolated task  to do to test this hypothesis


Understand our user - limited domain


We need to develop tests

**preprocess prompt step**


Train small adapter () on top of some LLM gets very good results
- make sure that stuff from our ?? is in the same embedding space
- Adapter which transforms KG into a text (google) or embedding (using small model - 7b params - how to train such small model) - looks nice
ConceptNet: ??? - what is it

---
Chat UI: OpenWebUI - self host it 

---
Research questions:
R1:  



