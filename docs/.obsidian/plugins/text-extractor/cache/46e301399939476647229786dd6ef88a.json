{"path":"02_Resources/Papers/2510.20345v1.pdf","text":"# Page 1^page=1\nPublished as a conference paper at ICAIS 2025 LLM-EMPOWERED KNOWLEDGE GRAPH CONSTRUC- TION: A SURVEY Haonan Bian Xidian University Xi’an China 23151214251@stu.xidian.edu.cn ABSTRACT Knowledge Graphs (KGs) have long served as a fundamental infrastructure for structured knowledge representation and reasoning. With the advent of Large Language Models (LLMs), the construction of KGs has entered a new paradigm—shifting from rule-based and statistical pipelines to language-driven and generative frameworks. This survey provides a comprehensive overview of recent progress in LLM-empowered knowledge graph construction, systemati- cally analyzing how LLMs reshape the classical three-layered pipeline of ontology engineering, knowledge extraction, and knowledge fusion. We first revisit traditional KG methodologies to establish conceptual foundations, and then review emerging LLM-driven approaches from two complementary per- spectives: schema-based paradigms, which emphasize structure, normalization, and consistency; and schema-free paradigms, which highlight flexibility, adapt- ability, and open discovery. Across each stage, we synthesize representative frameworks, analyze their technical mechanisms, and identify their limitations. Finally, the survey outlines key trends and future research directions, including KG-based reasoning for LLMs, dynamic knowledge memory for agentic systems, and multimodal KG construction. Through this systematic review, we aim to clar- ify the evolving interplay between LLMs and knowledge graphs, bridging sym- bolic knowledge engineering and neural semantic understanding toward the de- velopment of adaptive, explainable, and intelligent knowledge systems. 1 INTRODUCTION Knowledge Graphs (KGs) have long served as a cornerstone for representing, integrating, and rea- soning over structured knowledge. They provide a unified semantic foundation that underpins a wide range of intelligent applications, such as semantic search, question answering, and scientific discov- ery. Conventional KG construction pipelines are typically composed of three major components: ontology engineering, knowledge extraction, and knowledge fusion. Despite their success in en- abling large-scale knowledge organization, traditional paradigms (e.g., Zhong et al. (2023); Zhao et al. (2024)) continue to face three enduring challenges: (1) Scalability and data sparsity, as rule- based and supervised systems often fail to generalize across domains; (2) Expert dependency and rigidity, since schema and ontology design require substantial human intervention and lack adapt- ability; and (3) Pipeline fragmentation, where the disjoint handling of construction stages causes cu- mulative error propagation. These limitations hinder the development of self-evolving, large-scale, and dynamic KGs. The advent of Large Language Models (LLMs) introduces a transformative paradigm for over- coming these bottlenecks. Through large-scale pretraining and emergent generalization capabilities, LLMs enable three key mechanisms: (1) Generative knowledge modeling, synthesizing structured representations directly from unstructured text; (2) Semantic unification, integrating heterogeneous knowledge sources through natural language grounding; and (3) Instruction-driven orchestration, coordinating complex KG construction workflows via prompt-based interaction. Consequently, LLMs are evolving beyond traditional text-processing tools into cognitive engines that seamlessly bridge natural language and structured knowledge (e.g., Zhu et al. (2024b); Zhang & Soh (2024)). 1arXiv:2510.20345v1 [cs.AI] 23 Oct 2025\n\n# Page 2^page=2\nPublished as a conference paper at ICAIS 2025 This evolution marks a paradigm shift from rule-driven, pipeline-based systems toward LLM-driven, unified, and adaptive frameworks, where knowledge acquisition, organization, and reasoning emerge as interdependent processes within a generative and self-refining ecosystem (Pan et al., 2024). In light of these rapid advances, this paper presents a comprehensive survey of LLM-driven knowl- edge graph construction. We systematically review recent research spanning ontology engineering, knowledge extraction, and fusion, analyze emerging methodological paradigms, and highlight open challenges and future directions at the intersection of LLMs and knowledge representation. The remainder of this paper is organized as follows: • Section 2 introduces the foundations of traditional knowledge graph construction, covering ontology engineering, knowledge extraction, and fusion techniques prior to the LLM era. • Section 3 reviews LLM-enhanced ontology construction, encompassing both top-down paradigms (LLMs as ontology assistants) and bottom-up paradigms (KGs for LLMs). • Section 4 presents LLM-driven knowledge extraction, comparing schema-based and schema-free methodologies. • Section 5 discusses LLM-powered knowledge fusion, focusing on schema-level, instance- level, and hybrid frameworks. • Section 6 explores future research directions, including KG-based reasoning, dynamic knowledge memory, and multimodal KG construction. 2 PRELIMINARIES The construction of Knowledge Graphs (KGs) traditionally follows a three-layered pipeline com- prising ontology engineering, knowledge extraction, and knowledge fusion. Prior to the advent of Large Language Models (LLMs), these stages were implemented through rule-based, statistical, and symbolic approaches. This section briefly reviews these conventional methodologies to establish context for the subsequent discussion on LLM-empowered KG construction. 2.1 ONTOLOGY ENGINEERING Ontology Engineering (OE) involves the formal specification of domain concepts, relationships, and constraints. In the pre-LLM era, ontologies were primarily manually constructed by domain ex- perts, often supported by semantic web tools such as Prot´eg´e and guided by established methodolo- gies including METHONTOLOGY and On-To-Knowledge. These systematic processes emphasized conceptual rigor and logical consistency but required extensive expert intervention. As summarized by Zouaq & Nkambou (2010), ontology design during this period was char- acterized by strong human supervision and limited scalability. Subsequent semi-automatic ap- proaches—collectively known as ontology learning—sought to derive ontological structures from textual corpora, as reviewed in Asim et al. (2018). However, even advanced frameworks such as NeOn struggled with ontology evolution, modular reuse, and dynamic adaptation. As highlighted by Kotis et al. (2020), traditional OE frameworks offered precision and formal soundness but lacked flexibility and efficiency for large-scale or continuously evolving knowledge domains. 2.2 KNOWLEDGE EXTRACTION Knowledge Extraction (KE) aims to identify entities, relations, and attributes from unstructured or semi-structured data. Early approaches relied on handcrafted linguistic rules and pattern matching, which provided interpretability but were brittle and domain-specific. The evolution from symbolic and rule-based systems to statistical and neural methods has been systematically summarized in Pai et al. (2024). The advent of deep learning architectures, such as BiLSTM-CRF and Transformer-based models, marked a paradigm shift toward data-driven feature learning, as discussed by Yang et al. (2022b). Comprehensive analyses such as Detroja et al. (2023) further categorize supervised, weakly super- vised, and unsupervised relation extraction paradigms, emphasizing their dependence on annotated data and limited cross-domain generalization. 2\n\n# Page 3^page=3\nPublished as a conference paper at ICAIS 2025 In summary, traditional KE methods established the technical foundation for modern extraction pipelines but remained constrained by data scarcity, weak generalization, and cumulative error propagation—limitations that motivate the LLM-driven paradigms discussed in later sections. 2.3 KNOWLEDGE FUSION Knowledge Fusion (KF) focuses on integrating heterogeneous knowledge sources into a coherent and consistent graph by resolving issues of duplication, conflict, and heterogeneity. A central sub- task is entity alignment, which determines whether entities from different datasets refer to the same real-world object. Classical approaches relied on lexical and structural similarity measures, as reviewed in Zeng et al. (2021). The introduction of representation learning enabled embedding-based techniques that align entities within shared vector spaces, improving scalability and automation, as surveyed by Zhu et al. (2024a). Domain-specific applications, such as Yang et al. (2022a), demonstrate multi-feature fusion strategies combining structural, attribute, and relational similarities. Other graph-level models, such as Liu et al. (2022), further integrate semantic cues to enhance alignment robustness. Despite these advancements, traditional fusion pipelines continue to struggle with semantic hetero- geneity, large-scale integration, and dynamic knowledge updating—challenges that contempo- rary LLM-based fusion frameworks are increasingly designed to address. Figure 1: Taxonomy of LLM for KGC 3 LLM-ENHANCED ONTOLOGY CONSTRUCTION The integration of Large Language Models (LLMs) has introduced a fundamental paradigm shift in Ontology Engineering (OE) and, by extension, Knowledge Graph (KG) construction. Current research generally follows two complementary directions: a top-down approach, which leverages LLMs as intelligent assistants for formal ontology modeling, and a bottom-up approach, which employs ontology construction to enhance the reasoning and representation capabilities of LLMs themselves. 3.1 TOP-DOWN ONTOLOGY CONSTRUCTION: LLMS AS ONTOLOGY ASSISTANTS The top-down paradigm extends the traditions of the Semantic Web and Knowledge Engineering, emphasizing ontology development guided by predefined semantic requirements. Within this frame- work, LLMs serve as advanced co-modelers that assist human experts in translating natural language specifications—such as competency questions (CQs), user stories, or domain descriptions—into formal ontologies, typically represented in OWL or related standards. This paradigm prioritizes conceptual abstraction, the precise definition of relations, and structured semantic representation to 3\n\n# Page 4^page=4\nPublished as a conference paper at ICAIS 2025 ensure that subsequent knowledge extraction and instance population adhere to well-defined logical constraints. 3.1.1 COMPETENCY QUESTION (CQ)-BASED ONTOLOGY CONSTRUCTION CQ-based methods represent a requirements-driven pathway toward automated ontology modeling. In this setting, LLMs parse CQs or user stories to identify, categorize, and formalize domain-specific concepts, attributes, and relationships. A pioneering framework, Ontogenia (Lippolis et al., 2025a), introduced the use of Metacogni- tive Prompting for ontology generation, enabling the model to perform self-reflection and struc- tural correction during synthesis. By incorporating Ontology Design Patterns (ODPs), Ontogenia improves both the consistency and complexity of generated ontologies. Similarly, the CQbyCQ framework (Saeedizade & Blomqvist, 2024) demonstrated that LLMs can directly translate CQs and user stories into OWL-compliant schemas, effectively automating the transition from requirements to structured ontological models. Building on these advances, Lippolis et al. (2025b) proposed two complementary prompting strate- gies: a “memoryless” approach for modular construction and a reflective iterative method inspired by Ontogenia. Empirical evaluations revealed that LLMs can autonomously identify classes, ob- ject properties, and data properties, while generating corresponding logical axioms with consistency comparable to that of junior human modelers. Collectively, these studies have led to semi-automated ontology construction pipelines encompassing the entire lifecycle—from CQ formulation and val- idation to ontology instantiation—with human experts intervening only at critical checkpoints. Through this evolution, LLMs have transitioned from passive analytical tools to active modeling collaborators in ontology design. 3.1.2 NATURAL LANGUAGE-BASED ONTOLOGY CONSTRUCTION Beyond CQ-driven paradigms, natural language-based ontology construction seeks to induce seman- tic schemas directly from unstructured or semi-structured text corpora, eliminating the dependency on explicitly formulated questions. The goal is to enable LLMs to autonomously uncover conceptual hierarchies and relational patterns from natural language, achieving a direct mapping from textual descriptions to formal logical representations. Foundational work in this domain—including Saeedizade & Blomqvist (2024) and Lippolis et al. (2025b)—systematically evaluated GPT-4’s performance and confirmed that its outputs approach the quality of novice human modelers, thereby validating the feasibility of “intelligent ontology assis- tants.” The LLMs4OL framework (Giglou et al., 2023) further verified LLMs’ capacity for concept identification, relation extraction, and semantic pattern induction in general-purpose domains. Like- wise, Mateiu & Groza (2023) demonstrated the use of fine-tuned models to directly translate natural language into OWL axioms within established ontology editors such as Prot´eg´e. Recent systems such as NeOn-GPT (Fathallah et al., 2025) and LLMs4Life (Fathallah et al., 2024) have advanced this direction by introducing end-to-end, prompt-driven workflows that in- tegrate ontology reuse and adaptive refinement to construct deep, coherent ontological structures in complex scientific domains (e.g., life sciences). Meanwhile, lightweight frameworks such as LKD-KGC (Sun et al., 2025) enable rapid schema induction for open-domain knowledge graphs by clustering entity types extracted from document summaries. In summary, top-down research on LLM-assisted ontology construction emphasizes semantic con- sistency, structural completeness, and human–AI collaboration, marking a significant evolution of traditional knowledge engineering toward more intelligent, language-driven paradigms. 3.2 BOTTOM-UP ONTOLOGY SCHEMA CONSTRUCTION: KGS FOR LLMS The bottom-up methodology has gained increasing attention as a response to paradigm shifts intro- duced by the era of Large Language Models (LLMs), particularly within Retrieval-Augmented Gen- eration (RAG) frameworks. In this paradigm, the knowledge graph is no longer viewed merely as a static repository of structured knowledge for human interpretation. Instead, it serves as a dynamic infrastructure that provides factual grounding and structured memory for LLMs. Consequently, re- 4\n\n# Page 5^page=5\nPublished as a conference paper at ICAIS 2025 search focus has shifted from manually designing ontological hierarchies to automatically inducing schemas from unstructured or semi-structured data. This evolution can be delineated through three interrelated stages of progress. Early studies such as GraphRAG (Edge et al., 2024) and OntoRAG (Tiwari et al., 2025) established the foundation for data-driven ontology construction. These approaches first generate instance-level graphs from raw text via open information extraction, and then abstract ontological concepts and relations through clustering and generalization. This “data-to-schema” process transforms empirical knowledge into reusable conceptual structures, illustrating how instance-rich corpora can give rise to ontological blueprints. Building upon this foundation, the EDC (Extract–Define–Canonicalize) framework (Zhang & Soh, 2024) advanced the pipeline into a three-stage process consisting of open extraction, semantic defi- nition, and schema normalization. It enables the alignment of automatically induced schemas with existing ontologies, or the creation of new ones when predefined structures are absent. Extending this adaptability, AdaKGC (Ye et al., 2023) addressed the challenge of dynamic schema evolution, allowing models to incorporate novel relations and entity types without retraining. Collectively, these advances shift the focus from static schema construction toward continuous schema adapta- tion within evolving knowledge environments. More recent efforts have transitioned beyond algorithmic prototypes toward deployable knowledge systems. For example, AutoSchemaKG (Bai et al., 2025) integrates schema-based and schema- free paradigms within a unified architecture, supporting the real-time generation and evolution of enterprise-scale knowledge graphs. In this stage, KGs operate as a form of external knowledge memory for LLMs—prioritizing factual coverage, scalability, and maintainability over purely se- mantic completeness. This transformation marks a pragmatic reorientation of ontology construction, emphasizing its service to LLM reasoning and interpretability in knowledge-intensive applications. In summary, bottom-up ontology schema construction redefines the interplay between LLMs and knowledge engineering. The focus evolves from “LLMs for Ontology Engineering” to “Ontolo- gies and KGs for LLMs”. Whereas the top-down trajectory emphasizes semantic modeling, logical consistency, and expert-guided alignment—positioning LLMs as intelligent assistants in ontology design—the bottom-up trajectory prioritizes automatic extraction, schema induction, and dynamic evolution. This progression advances toward self-updating, interpretable, and scalable knowledge ecosystems that strengthen the grounding and reasoning capabilities of LLMs. 4 LLM-DRIVEN KNOWLEDGE EXTRACTION Through a systematic examination of recent advances, it becomes evident that methodologies for Large Language Model (LLM)-driven knowledge extraction have evolved along two princi- pal paradigms: schema-based extraction, which operates under explicit structural guidance, and schema-free extraction, which transcends the limitations of predefined templates. The former em- phasizes normalization, structural consistency, and semantic alignment, while the latter prioritizes adaptability, openness, and exploratory discovery. Together, these paradigms delineate the concep- tual landscape of contemporary research in LLM-based knowledge extraction. 4.1 SCHEMA-BASED METHODS The central principle of schema-based extraction lies in its reliance on an explicit knowledge schema that provides both structural guidance and semantic constraints for the extraction process. Within this paradigm, the research trajectory demonstrates a clear evolution—from the use of static onto- logical blueprints toward adaptive and dynamically evolving schema frameworks. 4.1.1 STATIC SCHEMA-DRIVEN EXTRACTION Early studies in LLM-driven knowledge extraction predominantly employed predefined, static schemas that rigidly constrained the extraction process. In this paradigm, the ontology functions as a fixed semantic backbone, directing the LLM to populate the knowledge base under strict structural supervision. The progression of this research line can be broadly characterized by three develop- mental stages. 5\n\n# Page 6^page=6\nPublished as a conference paper at ICAIS 2025 Initial efforts, such as Kommineni et al. (2024), utilized fully predefined ontological structures to ensure precision and interpretability. In their pipeline, the LLM first generates Competency Ques- tions (CQs) to delineate the knowledge scope, constructs the corresponding ontology (TBox), and subsequently performs ABox population under explicit schema supervision—achieving high con- sistency but limited flexibility. Similarly, the KARMA framework (Lu & Wang, 2025) adopts a multi-agent architecture, in which each agent executes schema-guided extraction tasks to guarantee accurate entity normalization and relation classification within a fixed ontological boundary. Building on these rigid frameworks, subsequent studies sought to enhance modularity and reusability through staged prompting. For instance, Feng et al. (2024) proposed a two-step “ontology-grounded extraction” approach: first generating a domain-specific ontology directly from text, and then lever- aging it as a directive prompt for RDF triple extraction. This approach strengthens structural align- ment while maintaining partial adaptability. More recent developments introduce localized flexibility within otherwise static frameworks. ODKE+ (Khorshidi et al., 2025) proposes ontology snippets—dynamically selected ontology sub- sets—to construct context-aware prompts tailored to specific entities, thus enabling limited schema adaptation at runtime. Likewise, Bhattarai et al. (2024) utilize the medical ontology UMLS to dy- namically generate task-specific prompts for clinical information extraction. Although these meth- ods introduce local adaptability, they remain bounded by pre-existing macro-schemas, representing a transitional phase toward schema dynamism. In summary, static schema-driven extraction forms the foundational paradigm of LLM-assisted knowledge extraction, emphasizing precision, logical consistency, and interpretability. However, its dependence on rigid ontological templates restricts scalability and cross-domain generalization. The progression from fixed schema control to selective, context-aware schema prompting marks the field’s gradual shift toward more adaptive, data-responsive frameworks. 4.1.2 DYNAMIC AND ADAPTIVE SCHEMA-BASED EXTRACTION Recent approaches reconceptualize the schema as a dynamic, evolving component of the extraction process rather than a fixed template—a shift from schema guiding extraction to schema co-evolving with it. AutoSchemaKG (Bai et al., 2025) exemplifies this trend by inducing schemas from large-scale cor- pora via unsupervised clustering and relation discovery. It employs multi-stage prompts tailored to different relation types, enabling the schema to evolve iteratively with extracted content and im- proving open-domain scalability. Building on this idea, AdaKGC (Ye et al., 2023) tackles schema drift through two mechanisms: the Schema-Enriched Prefix Instruction (SPI) for context-aware prompting and the Schema-Constrained Dynamic Decoding (SDD) for schema adaptation without retraining. Together, these methods enable adaptive schema learning, bridging symbolic structure and data- driven flexibility. They lay the groundwork for continual, self-updating knowledge graph construc- tion where extraction and schema evolution progress synergistically. 4.2 SCHEMA-FREE METHODS In contrast to paradigms that depend on externally defined blueprints, schema-free extraction aims to acquire structured knowledge directly from unstructured text without relying on any predefined ontology or relation schema. The central idea is to leverage Large Language Models (LLMs) as autonomous extractors capable of identifying entities and relations through advanced prompt engi- neering, instruction tuning, and self-organizing reasoning. The evolution of this paradigm unfolds along two major trajectories: structured generative extraction and open information extraction. 4.2.1 STRUCTURED GENERATIVE EXTRACTION The first trajectory, structured generative extraction, focuses on prompting LLMs to construct an implicit or on-the-fly schema during generation. Although no external ontology is provided, struc- tured reasoning patterns and generative templates guide the model toward consistent and coherent knowledge generation. 6\n\n# Page 7^page=7\nPublished as a conference paper at ICAIS 2025 Early studies, such as Nie et al. (2024), integrated the extraction process with Chain-of-Thought (CoT) prompting, encouraging stepwise reasoning for entity and relation identification. This ap- proach demonstrated that explicit schemas can be effectively replaced by reasoning-driven organiza- tion. Building on this insight, AutoRE (Xue et al., 2024) introduced an RHF (Relation–Head–Facts) pipeline via instruction fine-tuning, enabling the model to internalize relational regularities and im- prove coherence and scalability across documents. Subsequent works further enhanced schema-free extraction by incorporating retrieval and interac- tivity. For instance, Papaluca et al. (2024) proposed a Retrieval-Augmented prompting framework that dynamically enriches the context window with semantically related exemplars, thereby improv- ing factual precision. In parallel, ChatIE (Wei et al., 2024) reformulated extraction as a multi- turn dialogue process, wherein the model iteratively refines entity and relation candidates through chained question answering. Similarly, KGGEN (Mo et al., 2025) decomposed extraction into two sequential LLM invocations—first detecting entities, then generating relations—to reduce cognitive load and mitigate error propagation. Collectively, these studies reveal that even without explicit schemas, LLMs can internalize latent re- lational structures through guided reasoning, modular prompting, and interactive refinement—laying the groundwork for open-ended and self-organizing knowledge generation. 4.2.2 OPEN INFORMATION EXTRACTION (OIE) Open Information Extraction (OIE) extends structured generative methods toward schema-free extraction, aiming to discover all possible entity–relation–object triples from text without relying on predefined types. The EDC framework (Zhang & Soh, 2024) exemplifies this paradigm: its Extract stage uses few-shot prompting to generate comprehensive natural-language triples, producing a raw open knowledge graph that later undergoes definition and canonicalization. OIE prioritizes coverage and discovery over structural regularity. When combined with schema induction or canonicalization, it bridges unstructured text and emergent ontological organization—completing the continuum from schema-free to schema-generative knowledge construction. 5 LLM-POWERED KNOWLEDGE FUSION An examination of recent advances and pioneering studies indicates that methodologies leveraging Large Language Models (LLMs) for knowledge fusion predominantly address challenges at two fundamental levels: (1) constructing a unified and normalized knowledge skeleton at the schema layer, and (2) integrating and aligning the specific knowledge flesh at the instance layer. According to this distinction, existing approaches can be categorized into three major classes: schema-level fusion, instance-level fusion, and hybrid frameworks that integrate both. 5.1 SCHEMA-LEVEL FUSION Schema-level fusion unifies the structural backbone of knowledge graphs—concepts, entity types, relations, and attributes—into a coherent and semantically consistent schema. By aligning heteroge- neous elements, it ensures that all knowledge adheres to a unified conceptual specification. Research in this area has evolved through three major phases. (1) Ontology-driven consistency. Early work relied on explicit ontologies as global constraints. For instance, Kommineni et al. (2024) enforced alignment between extracted triples and predefined ontological definitions, achieving high semantic consistency but limited flexibility across domains. (2) Data-driven unification. To overcome this rigidity, LKD-KGC (Sun et al., 2025) introduced adaptive, embedding-based schema integration. It automatically extracts and merges equivalent en- tity types via vector clustering and LLM-based deduplication, allowing schema alignment to emerge dynamically from data. (3) LLM-enabled canonicalization. Recent approaches such as EDC (Zhang & Soh, 2024) extend fusion toward semantic canonicalization. By prompting LLMs to generate natural language defini- tions of schema components and comparing them via vector similarity, this method supports both self-alignment and cross-schema mapping with greater automation and semantic precision. 7\n\n# Page 8^page=8\nPublished as a conference paper at ICAIS 2025 In summary, schema-level fusion has progressed from ontology-driven to data-driven to LLM- enabled paradigms—marking a shift from rigid rule-based alignment toward flexible, semantics- oriented fusion mediated by LLM reasoning. 5.2 INSTANCE-LEVEL FUSION Instance-level fusion integrates concrete knowledge instances by addressing entity alignment, dis- ambiguation, deduplication, and conflict resolution. Its goal is to reconcile heterogeneous or redundant entities to maintain a coherent and semantically precise knowledge graph. Recent work reflects a clear evolution—from heuristic clustering to structured, reasoning-based frameworks. Early studies such as KGGEN (Mo et al., 2025) employed iterative LLM-guided clustering to merge equivalent entities and relations beyond surface matching. The framework performs pro- gressive triple extraction followed by semantic grouping, revealing the potential of LLMs to ag- gregate semantically related entities through implicit reasoning rather than explicit rules. Later, LLM-Align (Chen et al., 2024) and EntGPT (Ding et al., 2025) reframed alignment as a contextual reasoning task, using multi-step prompting to enhance semantic discrimination. LLM-Align treats alignment as a constrained multiple-choice problem, while EntGPT introduces a two-phase refine- ment pipeline that first generates candidate entities and then applies targeted reasoning for final selection, significantly improving alignment precision. More recent efforts incorporate structural and retrieval cues—e.g., Pons et al. (2025) leverage RAG-based fusion to exploit class–subclass hierarchies and entity descriptions for zero-shot disambiguation. This integration of graph topology enables more robust reasoning about unseen or ambiguous entities. Efficiency has also improved through hierarchical designs such as COMEM (Wang et al., 2024), which combines lightweight fil- tering with fine-grained reasoning. By cascading smaller and larger LLMs in a multi-stage pipeline, it achieves substantial efficiency gains while maintaining high semantic accuracy in large-scale fu- sion tasks. Overall, LLMs have evolved from simple matchers to adaptive reasoning agents that integrate contextual, structural, and retrieved signals for scalable, self-correcting fusion—paving the way toward autonomous knowledge graph construction. 5.3 COMPREHENSIVE AND HYBRID FRAMEWORKS Comprehensive and hybrid frameworks unify schema-level and instance-level fusion within a sin- gle, end-to-end workflow, moving beyond traditional modular pipelines toward integrated, prompt- driven architectures. The KARMA framework (Lu & Wang, 2025) exemplifies a multi-agent design where specialized agents collaboratively handle schema alignment, conflict resolution, and quality evaluation, achiev- ing scalability and global consistency. Building on this, ODKE+ (Khorshidi et al., 2025) employs an ontology-guided workflow coupling schema supervision with instance-level corroboration for improved semantic fidelity. More recently, Graphusion (Yang et al., 2024) introduces a unified, prompt-based paradigm that performs all fusion subtasks—alignment, consolidation, and infer- ence—within a single generative cycle. Together, these frameworks signal a shift toward integrated, adaptive, and generative fusion sys- tems, marking a crucial step toward autonomous, self-evolving knowledge graphs capable of con- tinuous construction and reasoning in LLM-driven ecosystems. 6 FUTURE APPLICATIONS Research at the intersection of Large Language Models (LLMs) and Knowledge Graphs (KGs) is progressively advancing toward deeper intelligent interaction and greater autonomy in knowl- edge representation and reasoning. In light of these developments, several promising directions are emerging for future exploration. 8\n\n# Page 9^page=9\nPublished as a conference paper at ICAIS 2025 6.1 KNOWLEDGE GRAPH-BASED REASONING FOR LLMS Future work is expected to further integrate structured KGs into the reasoning mechanisms of LLMs, enhancing their logical consistency, causal inference, and interpretability. This research direction signifies not only an improvement in reasoning capabilities but also a conceptual transition from knowledge construction to knowledge-driven reasoning. High-quality, well-structured KGs will provide the foundation for explainable and verifiable model inference. Existing studies such as KG- based Random-Walk Reasoning (Kim et al., 2024) and KG-RAR (Wu et al., 2025) have demonstrated the potential of this paradigm. A crucial complementary challenge, however, lies in how enhanced reasoning abilities can in turn support more robust and automated KG construction—forming a self- improving, virtuous cycle between knowledge building and reasoning. 6.2 DYNAMIC KNOWLEDGE MEMORY FOR AGENTIC SYSTEMS Achieving autonomy in LLM-powered agents requires overcoming the limits of finite context win- dows through persistent, structured memory. Recent architectures envision the knowledge graph (KG) as a dynamic memory substrate, evolving continuously with agent interactions rather than storing static histories. Frameworks such as A-MEM (Xu et al., 2025) model memory as intercon- nected “notes” enriched with contextual metadata, enabling continual reorganization and growth. Similarly, Zep (Rasmussen et al., 2025) employs a temporal knowledge graph (TKG) to manage fact validity and support time-aware reasoning and updates. These advances highlight dynamic KGs as long-term, interpretable memory systems that enable continuous learning, multi-agent collab- oration, and self-reflective reasoning. Future work will focus on improving scalability, temporal coherence, and multimodal integration for fully autonomous, knowledge-grounded agents. 6.3 MULTIMODAL KNOWLEDGE GRAPH CONSTRUCTION Multimodal Knowledge Graph (MMKG) construction aims to integrate heterogeneous modali- ties—such as text, images, audio, and video—into unified, structured representations that enable richer reasoning and cross-modal alignment. Representative work includes VaLiK (Vision-align- to-Language integrated KG) (Liu et al., 2025), which cascades pretrained Vision-Language Models (VLMs) to translate visual features into textual form, followed by a cross-modal verification module to filter noise and assemble MMKGs. This process achieves entity–image linkage without manual annotation. Beyond structure, representation learning methods such as KG-MRI (Lu et al., 2024) employ multimodal embeddings with contrastive objectives to align heterogeneous modalities into coherent semantic spaces. Key challenges remain in modality heterogeneity, alignment noise, scal- ability, and robustness under missing or imbalanced modalities. As LLMs and VLMs continue to co-evolve, MMKGs will become a cornerstone for bridging perceptual input and symbolic reasoning across modalities. 6.4 NEW ROLES FOR KGS IN LLM APPLICATIONS: BEYOND RAG Beyond their use as retrieval backbones in RAG systems, Knowledge Graphs (KGs) are increasingly envisioned as a cognitive middle layer bridging raw input and LLM reasoning. In this paradigm, KGs provide a structured scaffold for querying, planning, and decision-making, enabling more interpretable and grounded generation. Recent studies illustrate this shift. CogER (Bing et al., 2023) formulates recommendation as cognition-aware KG reasoning, integrating intuitive and path- based inference for explainability. In the biomedical domain, PKG-LLM (Sarabadani et al., 2025) employs domain KGs for knowledge augmentation and predictive modeling in mental health diag- nostics. Together, these approaches treat the KG as an interactive reasoning substrate, promising more robust and explainable generation in domains such as science, code, and healthcare. 7 CONCLUSION This survey presents a comprehensive overview of how Large Language Models (LLMs) are trans- forming Knowledge Graph (KG) construction across ontology engineering, knowledge extraction, and knowledge fusion. LLMs shift the paradigm from rule-based and modular pipelines toward unified, adaptive, and generative frameworks. Across these stages, three trends emerge: (1) the 9\n\n# Page 10^page=10\nPublished as a conference paper at ICAIS 2025 evolution from static schemas to dynamic induction, (2) the integration of pipeline modularity into generative unification, and (3) the transition from symbolic rigidity to semantic adaptability. To- gether, these shifts redefine KGs as living, cognitive infrastructures that blend language under- standing with structured reasoning. Despite remarkable progress, challenges remain in scalability, reliability, and continual adaptation. Future advances in prompt design, multimodal integration, and knowledge-grounded reasoning will be key to realizing autonomous and explainable knowledge- centric AI systems. REFERENCES Muhammad Nabeel Asim, Muhammad Wasim, Muhammad Usman Ghani Khan, Waqar Mah- mood, and Hafiza Mahnoor Abbasi. A survey of ontology learning techniques and applications. Database, 2018:bay101, 2018. Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, and Yangqiu Song. AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora. arXiv preprint arXiv:2505.23628, aug 2025. doi: 10.48550/arXiv.2505.23628. URL http: //arxiv.org/abs/2505.23628. Kriti Bhattarai, Inez Y. Oh, Zachary B. Abrams, and Albert M. Lai. Document-level Clinical Entity and Relation extraction via Knowledge Base-Guided Generation. In Proceedings of the 23rd Workshop on Biomedical Natural Language Processing, pp. 318–327, Bangkok, Thailand, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.bionlp-1.24. URL https: //aclanthology.org/2024.bionlp-1.24. Qingyu Bing, Qiannan Zhu, and Zhicheng Dou. Cognition-aware Knowledge Graph Reasoning for Explainable Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, pp. 402–410, Singapore, Singapore, feb 2023. ACM. doi: 10.1145/ 3539597.3570391. URL https://dl.acm.org/doi/10.1145/3539597.3570391. Xuan Chen, Tong Lu, and Zhichun Wang. LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs. arXiv preprint arXiv:2412.04690, dec 2024. doi: 10.48550/ arXiv.2412.04690. URL http://arxiv.org/abs/2412.04690. Kartik Detroja, CK Bhensdadia, and Brijesh S Bhatt. A survey on relation extraction. Intelligent Systems with Applications, 19:200244, 2023. Yifan Ding, Amrit Poudel, Qingkai Zeng, Tim Weninger, Balaji Veeramani, and Sanmitra Bhat- tacharya. EntGPT: Entity Linking with Generative Large Language Models. arXiv preprint arXiv:2402.06738, may 2025. doi: 10.48550/arXiv.2402.06738. URL http://arxiv.org/ abs/2402.06738. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From Local to Global: A Graph RAG Approach to Query-Focused Sum- marization. arXiv preprint arXiv:2404.16130, apr 2024. doi: 10.48550/arXiv.2404.16130. URL http://arxiv.org/abs/2404.16130. Nadeen Fathallah, Steffen Staab, and Alsayed Algergawy. LLMs4Life: Large Language Models for Ontology Learning in Life Sciences. arXiv preprint arXiv:2412.02035, dec 2024. doi: 10.48550/ arXiv.2412.02035. URL http://arxiv.org/abs/2412.02035. Nadeen Fathallah, Arunav Das, Stefano De Giorgis, Andrea Poltronieri, Peter Haase, and Liubov Kovriguina. NeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning. In Albert Mero˜no Pe˜nuela, Oscar Corcho, Paul Groth, Elena Simperl, Valentina Tamma, An- drea Giovanni Nuzzolese, Maria Poveda-Villal´on, Marta Sabou, Valentina Presutti, Irene Celino, Artem Revenko, Joe Raad, Bruno Sartini, and Pasquale Lisena (eds.), The Semantic Web: ESWC 2024 Satellite Events, volume 15344, pp. 36–50. Springer Nature Switzerland, Cham, 2025. doi: 10.1007/978-3-031-78952-6 4. URL https://link.springer.com/10.1007/ 978-3-031-78952-6_4. 10\n\n# Page 11^page=11\nPublished as a conference paper at ICAIS 2025 Xiaohan Feng, Xixin Wu, and Helen Meng. Ontology-grounded Automatic Knowledge Graph Con- struction by LLM under Wikidata schema. arXiv preprint arXiv:2412.20942, dec 2024. doi: 10.48550/arXiv.2412.20942. URL http://arxiv.org/abs/2412.20942. Hamed Babaei Giglou, Jennifer D’Souza, and S¨oren Auer. LLMs4OL: Large Language Models for Ontology Learning. arXiv preprint arXiv:2307.16648, aug 2023. doi: 10.48550/arXiv.2307. 16648. URL http://arxiv.org/abs/2307.16648. Samira Khorshidi, Azadeh Nikfarjam, Suprita Shankar, Yisi Sang, Yash Govind, Hyun Jang, Ali Kasgari, Alexis McClimans, Mohamed Soliman, Vishnu Konda, Ahmed Fakhry, and Xiaoguang Qi. ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs. arXiv preprint arXiv:2509.04696, sep 2025. doi: 10.48550/arXiv.2509.04696. URL http://arxiv.org/ abs/2509.04696. Yejin Kim, Eojin Kang, Juae Kim, and H. Howie Huang. Causal Reasoning in Large Language Models: A Knowledge Graph Approach. arXiv preprint arXiv:2410.11588, oct 2024. doi: 10. 48550/arXiv.2410.11588. URL http://arxiv.org/abs/2410.11588. Vamsi Krishna Kommineni, Birgitta K¨onig-Ries, and Sheeba Samuel. Towards the automation of knowledge graph construction using large language models. Journal Name, 2024. Konstantinos I. Kotis, George A. Vouros, and Dimitris Spiliotopoulos. Ontology engineer- ing methodologies for the evolution of living and reused ontologies: status, trends, findings and recommendations. The Knowledge Engineering Review, 35:e4, 2020. doi: 10.1017/ S0269888920000065. Anna Sofia Lippolis, Miguel Ceriani, Sara Zuppiroli, and Andrea Giovanni Nuzzolese. Ontoge- nia: Ontology Generation with Metacognitive Prompting in Large Language Models. In Al- bert Mero˜no Pe˜nuela, Oscar Corcho, Paul Groth, Elena Simperl, Valentina Tamma, Andrea Gio- vanni Nuzzolese, Maria Poveda-Villal´on, Marta Sabou, Valentina Presutti, Irene Celino, Artem Revenko, Joe Raad, Bruno Sartini, and Pasquale Lisena (eds.), The Semantic Web: ESWC 2024 Satellite Events, volume 15344, pp. 259–265. Springer Nature Switzerland, Cham, 2025a. doi: 10.1007/978-3-031-78952-6 38. URL https://link.springer.com/10.1007/ 978-3-031-78952-6_38. Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskis¨arkk¨a, Sara Zuppiroli, Miguel Ceriani, Aldo Gangemi, Eva Blomqvist, and Andrea Giovanni Nuzzolese. Ontology Generation using Large Language Models. arXiv preprint arXiv:2503.05388, mar 2025b. doi: 10.48550/ arXiv.2503.05388. URL http://arxiv.org/abs/2503.05388. Junming Liu, Siyuan Meng, Yanting Gao, Song Mao, Pinlong Cai, Guohang Yan, Yirong Chen, Zilin Bian, Ding Wang, and Botian Shi. Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning. arXiv preprint arXiv:2503.12972, jul 2025. doi: 10.48550/arXiv.2503.12972. URL http://arxiv.org/ abs/2503.12972. Shuang Liu, Man Xu, Yufeng Qin, and Niko Lukaˇc. Knowledge graph alignment network with node-level strong fusion. Applied Sciences, 12(19), 2022. doi: 10.3390/app12199434. URL https://www.mdpi.com/2076-3417/12/19/9434. Yuxing Lu and Jinzhuo Wang. KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment. arXiv preprint arXiv:2502.06472, feb 2025. doi: 10.48550/arXiv.2502.06472. URL http://arxiv.org/abs/2502.06472. Yuxing Lu, Weichen Zhao, Nan Sun, and Jinzhuo Wang. Enhancing multimodal knowledge graph representation learning through triple contrastive learning. In Kate Larson (ed.), Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-24, pp. 5963– 5971. International Joint Conferences on Artificial Intelligence Organization, aug 2024. doi: 10.24963/ijcai.2024/659. URL https://doi.org/10.24963/ijcai.2024/659. Main Track. 11\n\n# Page 12^page=12\nPublished as a conference paper at ICAIS 2025 Patricia Mateiu and Adrian Groza. Ontology engineering with Large Language Models. arXiv preprint arXiv:2307.16699, jul 2023. doi: 10.48550/arXiv.2307.16699. URL http://arxiv. org/abs/2307.16699. Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanat- soulis, and Sanmi Koyejo. KGGen: Extracting Knowledge Graphs from Plain Text with Lan- guage Models. arXiv preprint arXiv:2502.09956, feb 2025. doi: 10.48550/arXiv.2502.09956. URL http://arxiv.org/abs/2502.09956. Jixuan Nie, Xia Hou, Wenfeng Song, Xuan Wang, Xinyu Zhang, Xingliang Jin, Shuozhe Zhang, and Jiaqi Shi. Knowledge graph efficient construction: Embedding chain-of-thought into llms. Proceedings of the VLDB Endowment. ISSN, 2150:8097, 2024. Liu Pai, Wenyang Gao, Wenjie Dong, Lin Ai, Ziwei Gong, Songfang Huang, Li Zongsheng, Ehsan Hoque, Julia Hirschberg, and Yue Zhang. A survey on open information extraction from rule-based model to large language model. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Findings of the Association for Computational Linguistics: EMNLP 2024, pp. 9586–9608, Miami, Florida, USA, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-emnlp.560. URL https://aclanthology.org/2024. findings-emnlp.560/. Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. Unifying large language models and knowledge graphs: A roadmap. IEEE Transactions on Knowledge and Data Engineering, 36(7):3580–3599, 2024. Andrea Papaluca, Daniel Krefl, Sergio Rodr´ıguez M´endez, Artem Lensky, and Hanna Suominen. Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large Language Models. In Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024), pp. 12–23, Bangkok, Thailand, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.kallm-1.2. URL https://aclanthology.org/2024.kallm-1.2. Gerard Pons, Besim Bilalli, and Anna Queralt. Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation. arXiv preprint arXiv:2505.02737, pp. 162–179, 2025. doi: 10.1007/978-3-031-77844-5 9. URL http://arxiv.org/abs/2505.02737. Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, and Daniel Chalef. Zep: A Temporal Knowledge Graph Architecture for Agent Memory. arXiv preprint arXiv:2501.13956, jan 2025. doi: 10.48550/arXiv.2501.13956. URL http://arxiv.org/abs/2501.13956. Mohammad Javad Saeedizade and Eva Blomqvist. Navigating Ontology Development with Large Language Models. In Albert Mero˜no Pe˜nuela, Anastasia Dimou, Rapha¨el Troncy, Olaf Hartig, Maribel Acosta, Mehwish Alam, Heiko Paulheim, and Pasquale Lisena (eds.), The Semantic Web, volume 14664, pp. 143–161. Springer Nature Switzerland, Cham, 2024. doi: 10.1007/978-3-031-60626-7 8. URL https://link.springer.com/10.1007/ 978-3-031-60626-7_8. Ali Sarabadani, Hadis Taherinia, Niloufar Ghadiri, Ehsan Karimi Shahmarvandi, and Ramin Mousa. PKG-LLM: A Framework for Predicting GAD and MDD Using Knowledge Graphs and Large Language Models in Cognitive Neuroscience. Preprints, feb 2025. doi: 10. 20944/preprints202502.0982.v1. URL https://www.preprints.org/manuscript/ 202502.0982/v1. Jiaqi Sun, Shiyou Qian, Zhangchi Han, Wei Li, Zelin Qian, Dingyu Yang, Jian Cao, and Guangtao Xue. LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing. arXiv preprint arXiv:2505.24163, may 2025. doi: 10.48550/arXiv.2505.24163. URL http://arxiv.org/abs/2505.24163. Yash Tiwari, Owais Ahmad Lone, and Mayukha Pal. OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases. arXiv preprint arXiv:2506.00664, may 2025. doi: 10.48550/arXiv.2506.00664. URL http://arxiv.org/ abs/2506.00664. 12\n\n# Page 13^page=13\nPublished as a conference paper at ICAIS 2025 Tianshu Wang, Xiaoyang Chen, Hongyu Lin, Xuanang Chen, Xianpei Han, Hao Wang, Zhenyu Zeng, and Le Sun. Match, compare, or select? an investigation of large language models for entity matching. arXiv preprint arXiv:2405.16884, 2024. Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, and Wenjuan Han. ChatIE: Zero-Shot Information Extraction via Chatting with ChatGPT. arXiv preprint arXiv:2302.10205, may 2024. doi: 10. 48550/arXiv.2302.10205. URL http://arxiv.org/abs/2302.10205. Wenjie Wu, Yongcheng Jing, Yingjie Wang, Wenbin Hu, and Dacheng Tao. Graph-Augmented Rea- soning: Evolving Step-by-Step Knowledge Graph Retrieval for LLM Reasoning. arXiv preprint arXiv:2503.01642, mar 2025. doi: 10.48550/arXiv.2503.01642. URL http://arxiv.org/ abs/2503.01642. Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, and Yongfeng Zhang. A-MEM: Agentic Memory for LLM Agents. arXiv preprint arXiv:2502.12110, oct 2025. doi: 10.48550/arXiv. 2502.12110. URL http://arxiv.org/abs/2502.12110. Lilong Xue, Dan Zhang, Yuxiao Dong, and Jie Tang. AutoRE: Document-Level Relation Extraction with Large Language Models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pp. 211–220, Bangkok, Thailand, 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-demos.20. URL https://aclanthology.org/2024.acl-demos.20. Linyao Yang, Chen Lv, Xiao Wang, Ji Qiao, Weiping Ding, Jun Zhang, and Fei-Yue Wang. Col- lective entity alignment for knowledge fusion of power grid dispatching knowledge graphs. IEEE/CAA Journal of Automatica Sinica, 9(11):1990–2004, 2022a. doi: 10.1109/JAS.2022. 105947. Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, and Irene Li. Graphusion: Leveraging Large Language Models for Scientific Knowl- edge Graph Fusion and Construction in NLP Education. arXiv preprint arXiv:2407.10794, jul 2024. doi: 10.48550/arXiv.2407.10794. URL http://arxiv.org/abs/2407.10794. Yang Yang, Zhilei Wu, Yuexiang Yang, Shuangshuang Lian, Fengjie Guo, and Zhiwei Wang. A survey of information extraction based on deep learning. Applied Sciences, 12(19):9691, 2022b. Hongbin Ye, Honghao Gui, Xin Xu, Xi Chen, Huajun Chen, and Ningyu Zhang. Schema-adaptable Knowledge Graph Construction. arXiv preprint arXiv:2305.08703, nov 2023. doi: 10.48550/ arXiv.2305.08703. URL http://arxiv.org/abs/2305.08703. Kaisheng Zeng, Chengjiang Li, Lei Hou, Juanzi Li, and Ling Feng. A comprehensive survey of entity alignment for knowledge graphs. AI Open, 2:1–13, 2021. doi: https://doi.org/10.1016/j. aiopen.2021.02.002. URL https://www.sciencedirect.com/science/article/ pii/S2666651021000036. Bowen Zhang and Harold Soh. Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction. In Proceedings of the 2024 Conference on Empirical Meth- ods in Natural Language Processing, pp. 9820–9836, Miami, Florida, USA, 2024. Associa- tion for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.548. URL https: //aclanthology.org/2024.emnlp-main.548. Zhigang Zhao, Xiong Luo, Maojian Chen, and Ling Ma. A survey of knowledge graph construction using machine learning. CMES-Computer Modeling in Engineering & Sciences, 139(1), 2024. Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. A comprehensive survey on auto- matic knowledge graph construction. ACM Computing Surveys, 56(4):1–62, 2023. Beibei Zhu, Ruolin Wang, Junyi Wang, Fei Shao, and Kerun Wang. A survey: knowledge graph entity alignment research based on graph embedding. Artificial Intelligence Review, 57(9):229, 2024a. 13\n\n# Page 14^page=14\nPublished as a conference paper at ICAIS 2025 Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Hua- jun Chen, and Ningyu Zhang. Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities. World Wide Web, 27(5):58, 2024b. Amal Zouaq and Roger Nkambou. A Survey of Domain Ontology Engineering: Methods and Tools. In Roger Nkambou, Jacqueline Bourdeau, and Riichiro Mizoguchi (eds.), Advances in Intelligent Tutoring Systems, volume 308, pp. 103–119. Springer Berlin Heidelberg, Berlin, Hei- delberg, 2010. doi: 10.1007/978-3-642-14363-2 6. URL http://link.springer.com/ 10.1007/978-3-642-14363-2_6. 14\n\n","libVersion":"0.5.0","langs":""}