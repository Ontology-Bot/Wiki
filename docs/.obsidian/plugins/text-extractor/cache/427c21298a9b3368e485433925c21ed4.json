{"path":"02_Resources/Papers/artsiom_summary/2408.00800v2.pdf","text":"# Page 1^page=1\nChatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards Jonathan Reif∗, Tom Jeleniewski∗, Milapji Singh Gill∗, Felix Gehlhoff∗, Alexander Fay† ∗Institute of Automation Technology Helmut Schmidt University Hamburg, Germany {jonathan.reif, tom.jeleniewski, milapji.gill, felix.gehlhoff}@hsu-hh.de †Chair of Automation Ruhr University, Bochum, Germany alexander.fay@rub.de Abstract—The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An ex- perimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research. Index Terms—Semantic Web, Ontologies, Large Language Models, Cyber-Physical Systems, Industry 4.0 I. INTRODUCTION In the context of Cyber-Physical Systems (CPS) and In- dustry 4.0, domain-specific ontologies serve as highly ad- vantageous knowledge bases. Ontologies enable efficient data integration and enhance the interoperability of different CPS by establishing clear semantics and formalizing domain knowl- edge [1]. These attributes are particularly beneficial in in- dustrial applications where data is dispersed across various heterogeneous sources. Thus, ontologies are essential for man- aging the increasing complexity of CPS engineering, opera- tion, and maintenance. Particularly, their use within assistance systems in various Industry 4.0 application scenarios improves decision-making and optimizes processes across different life cycle phases of CPS [2, 3, 4]. However, significant challenges exist in facilitating inter- action between end users and ontologies. Ontologies are inherently complex and not easily understandable, making them difficult for end users to engage with effectively [5]. Traditionally, knowledge querying is conducted based on predefined Competency Questions (CQs) and static SPARQL Protocol and RDF Query Language (SPARQL) queries [1]. These are neither intuitive for someone without Semantic Web expertise nor user-friendly. Especially in view of the lack of ontology experts, this problem is even more critical [1]. Many users find it difficult to formulate complex SPARQL queries. This significantly limits the flexibility and efficiency of knowledge retrieval. In this context, the communication between a domain-specific ontology and an end user can be substantially improved by employing chatbots and Large Language Models (LLMs) [5, 6]. Currently, LLM-based assistance system experience in- creased significance, driven by the latest accomplishments in the LLM community. However, relying solely on LLM- based approaches poses significant risks. Due to the lack of traceability of LLMs and their potentially highly creative interpretative abilities, it cannot be ensured that the LLM extracts an answer directly from a credible source instead of creating its own probability-based responses. As a result, incorrect information could be conveyed to the user, potentially causing errors. This poses a significant threat, especially in industrial applications, where the accuracy and correctness of answers are crucial, and hallucinated responses generated by an LLM could have severe consequences. Therefore, it is beneficial to adopt an approach that combines the advantages of ontologies — the formal, structured provision of factual knowledge — with those of LLMs, which offer intuitive and easy use. For this reason, we propose a concept to improve the process of automated SPARQL query generation by leveraging LLMs and information from domain-specific standards. This approach aims to enhance user-friendliness by providing an intuitive interface for querying complex ontologies. The paper is structured as follows: In Sec. II, we intro- duce the requirements for the proposed concept and analyze related work concerning these requirements. Sec. III details the concept. Preliminary results from an initial experimental study are presented in Sec. IV. Finally, Sec. V summarizes the contribution and depicts future research directions. II. REQUIREMENTS AND RELATED WORK A. Requirements R1: Intuitive communication between the user and the individually created ontology As described in Sec. I the use of ontologies can pose sig- nificant challenges for non-experts. Therefore, one of the key requirements is to lower the usage barrier by assisting the user in their communication with the ontology. This involves creating an interface or a system that is user-friendly and intuitive, allowing users to interact with the ontology in a way that feels natural and straightforward. Thus, users should bearXiv:2408.00800v2 [cs.IR] 17 Oct 2024\n\n# Page 2^page=2\npermitted to formulate queries using their own words, rather than being required to use specific terms or codes [7]. R2: Flexible queries to the ontology based on the user’s current information requirements Given the need to facilitate the user’s interaction with the ontology, the second requirement is the ability to generate customized queries. These queries should be flexible and adapt to the user’s current information needs. This flexibility enhances the user-friendliness of the system and ensures that the user can extract the most relevant and useful information from the ontology [8]. R3: Accuracy and traceability of answers While making the ontology user-friendly is important, it would be futile if the information retrieved is not accurate [9]. There- fore, the third requirement is to guarantee the accuracy of the answers provided by the assistance-system. This requirement becomes even more critical in an industrial setting where the accuracy of information is paramount. In this context, the correctness of the answers additionally has to be traceable by users to ensure correctness as inaccurate information can lead to costly mistakes, inefficiencies, and even safety risks. Therefore, the system must be designed to provide precise, reliable, and traceable answers. B. Related Work Chen et al. [10] present a semantic embedding framework for Web Ontology Language (OWL) ontologies. It utilizes a combination of random walks and word embedding techniques to encode the semantics of OWL ontologies by considering their graph structure, lexical information, and logical construc- tors. The results suggest good accuracy. However, because the generation of answers is solely based on the use of an LLM, there is no traceability of the generated answers. Chen et al. [5] introduce a system designed to efficiently generate SPARQL queries for so-called question answering systems. The primary objective of the system is to reduce query costs while maintaining high accuracy in generating SPARQL queries, which are used to retrieve answers from databases. The approach employs a Recurrent Neural Network (RNN) to generate SPARQL queries from learned and labeled keywords. Building on this, Chen et al. [11] describe the enhancement of question answering systems through advanced Natural Language Processing (NLP) techniques and multi- label classification also using RNNs. They emphasize the use of NLP to interpret and process user queries in Natural Language (NL), converting them into a format that can be used to generate SPARQL queries effectively. This involves the use of technologies such as tokenization, lemmatization, and part-of-speech tagging to understand the semantic structure of the queries. Although both publications also pursue the idea of translating user questions into SPARQL queries, they refrain from using LLMs [5, 11]. However, Chen et al. [5] also emphasize that when converting a user question into query grammar, the accuracy of the generation of the query decides whether an answering system can provide a correct answer. Avila et al. [6] conducted preliminary experiments to eval- uate ChatGPT’s (GPT-3.5) ability to answer NL questions over a Knowledge Graph (KG) in domains such as families, people, and jobs. Various setups were tested, including direct answering and text-to-SPARQL translation using either or both the TBox and ABox of the KG. The results indicated that the text-to-SPARQL approach utilizing both the TBox and ABox yielded the best performance. Furthermore, Avila et al. [6] present a framework designed to optimize the translation of NL questions into SPARQL queries. It operates in two stages: an offline stage that generates indices mapping KG terms (TBox and ABox) to their Uniform Resource Identifiers (URIs), and an online stage that uses these indices to translate NL questions into SPARQL queries and generate responses. By reducing the number of tokens processed, the framework decreases the likelihood of hallucinations and enhances support for large KGs. However, the effect of providing explanations of the graph to the LLM as well as the level of complexity to which the LLM can generate SPARQL queries in an reliable manner where not examined. III. CONCEPT FOR CHATBOT-BASED INTERACTION WITH ONTOLOGIES In the following, a concept is introduced that utilizes a chatbot-based interface for user interactions with ontologies, providing flexible querying options. As mentioned in Sec. II, previous approaches utilize LLMs directly as a querying medium. However, this is associated with significant risks in industrial settings as explained in Sec. I. Therefore, our approach is based on maintaining SPARQL-based querying. To support domain-specific experts with limited expertise in handling Semantic Web technologies, LLMs are used in this approach to generate SPARQL queries. The approach is illustrated in Fig. 1. Fig. 1: Concept for LLM-based interaction with ontologies\n\n# Page 3^page=3\nUsers interact with the ontology via a chat interface, allow- ing them to pose questions that are processed in the backend. These queries are sent to the LLM through the ChatGPT API, incorporating predefined prompts, as explained in detail in Sec. III-1 and the TBox. By including only the TBox in the prompt, the security advantage is that the explicit ABox knowledge stays separate from the LLM and can only be accessed through SPARQL queries. This approach ensures that sensitive industrial information remains protected within the company’s internal systems. However, the LLM does not directly answer the input question. Instead, it uses the predefined prompt to transform the question into a SPARQL query. This query is then returned to the backend and executed at the SPARQL endpoint. The results are processed in the backend and displayed to the user through the user interface, providing the answers required. This approach ensures that the LLM produces no incorrect or fabricated answers, as only ”true” results that are embedded within the model are retrieved without invention or interpre- tation. However, while the responses are verifiable because they reflect the model’s actual knowledge, they are not fully validated. Errors may still persist in the generated queries, leading to answers that do not match the original question or, in some cases, no answers being returned at all. Considering that potential users may not be familiar with the terminology used in the ontology, it is crucial to accommodate their ability to accurately formulate questions via the chat interface. Special attention should be given to the following aspects to ensure effective user interaction: 1) Prompts: Given that neither the user nor the LLM is aware of the TBox associated with the ontology to be queried, it is essential to supplement the chat-based ques- tions with prompts that incorporate the required contextual knowledge. These prompts must comprehensively detail the TBox, encapsulating the modeling concepts and terminologies of the ontology. By integrating extensive descriptions of the ontology, including its classes, properties, and relations, within the prompts, the LLM can accurately interpret user questions and transform them into precise SPARQL queries. For this reason, the TBox containing the modeling concept should be transferred together with the user question. These prompts including the TBox serve as a guide for translating domain- specific knowledge into executable SPARQL queries, thus ensuring that the LLM grasps the necessary context and specifics for accurate query formulation. 2) Creating Ontology Design Patterns: In the industrial domain, fixed terminologies defined by industry standards are prevalent. For building ontologies, we employ Ontology Design Patterns (ODPs) that adhere to these established stan- dards, functioning as templates for creating knowledge graphs. Hildebrandt et al. [1] outline a methodological approach for building ontologies based on ODPs. When these aligned ODPs, resembling a TBox for the problem domain context, accompany the chat-based queries, the LLM can examine the structures and terminology to accurately translate the chat query into SPARQL in accordance with the ODPs. Enhancing ODPs with rdfs:comment annotations is crit- ical, as these provide additional context about the classes, object properties, and data properties. This extra layer of context assists the LLM in disambiguating terms that may be ambiguous or have multiple interpretations based on their literal meanings. By leveraging rdfs:comment, the LLM gains deeper insights into the intended semantics of the ontol- ogy elements, thereby enhancing its capability to accurately transform user questions into SPARQL queries. This strategy ensures that the generated queries are more closely aligned with the underlying ontology, minimizing misinterpretations and enhancing the reliability of the SPARQL queries. IV. PRELIMINARY RESULTS Experiments were conducted to assess the ability of LLMs to generate SPARQL queries consistent with the criteria out- lined in Sec. II. The study investigated factors affecting the quality of these queries to evaluate the practical use of LLMs in this domain. ChatGPT-4o was employed to create SPARQL queries for various ODPs, utilizing prompts that included specific ODP information in plain text and a corresponding question that the query aimed to answer. The ODPs used in the study were VDI 3682 (Formalized Process Description) [12], DIN EN 61360 (Property Descrip- tions of Technical Systems) [13], and VDI 2206 (Descriptions of Machine Structures) [14]. Questions were crafted in two styles to assess the influence of phrasing on query quality: Firstly, standard-compliant questions (SCQs) were posed, en- suring that the terminology adhered to established standards. Secondly, non-standard-compliant questions (NSCQs) were formulated, incorporating more generic terminology typical for a non-expert. Additionally, these questions were posed using ODPs both with and without annotations in rdfs:comment, aiming to determine if such comments enhance query quality. TABLE I: Examined question categories according to [15]Complexity Category SCQ Example ODP Boolean Is the sensor part of a module in the system? VDI 2206 Count How many technical resources are contained within the system? VDI 3682 Rank Could you provide the values contained in the model in as- cending order? DIN EN 61360 Simple Which process operators are performed in process X? VDI 3682 String Is there a DataElement with the name ”ResultAccuracy”? DIN EN 61360 Two Hop Which components are part of a module and which system in- cludes this module? VDI 2206 Two Intent Of which process operators is process X composed? To which technical resources are these process operators assigned? VDI 3682\n\n# Page 4^page=4\nThe complexity of questions was graded into seven cat- egories according to the scheme proposed by Rony et al. [15], shown in Tab. I. Boolean, Count, and Rank represent simpler queries to the ontology, intended to yield a True/False outcome, a numerical count, or a ranking, respectively. Simple, String, and Two Hop require querying more complex graph relationships or more specific words, necessitating a greater semantic understanding. Two Intent is the most complex cate- gory, as it essentially requires two responses and the merging of multiple triples. For each category, an example with a SCQ is listed in Tab. I, along with the corresponding ODP. Overall, the experimental study encompasses 28 questions for each ODP, resulting in a total of 84 questions with analyzed results. Preliminary results indicate a generally good performance of the tested LLM in generating SPARQL queries. In Tab. II, the questions categories, exhibiting similar patterns in the results, were classified into three clusters. The results show that simpler questions (Boolean, Count, Rank) generally yielded more accurate SPARQL queries, regardless of the presence of rdfs:comment in the tested ontologies. Moreover it was found that precise SCQ formulation significantly af- fected query quality. However, for more complex questions (e.g., Two Intent), ChatGPT-4o often generated inaccurate or imprecise queries, typically failing to identify the correct instance. The results also suggest that ODPs augmented with rdfs:comment produced queries with greater precision, supporting the hypothesis that detailed comments in ontolo- gies positively impact automated SPARQL query generation. Accordingly, it can be concluded that annotations enhance not only human comprehension of ontologies but also offer significant benefits for LLMs in terms of query generation accuracy and effectiveness. Overall the suitability of LLMs for (automated) SPARQL query generation could be shown. TABLE II: Preliminary Results: Percentage of correctly gen- erated SPARQL queries w/o comments commented Categories SCQs NSCQs SCQs NSCQs Boolean, Count, Rank 100% 100% 100% 100% Simple, String, Two Hop 89% 44% 100% 78% Two Intent 67% 0% 100% 67% V. SUMMARY AND FUTURE WORK This paper investigates the suitability of LLMs for gen- erating SPARQL queries to simplify user interaction with ontologies. By combining the intuitive usability of LLM- based chat applications with the formal, structured knowledge provision of ontologies, the proposed concept is particularly beneficial in an industrial context. An experimental study using ChatGPT-4o assessed the accuracy of SPARQL queries generated under various conditions and highlighted the value of incorporating rdfs:comment. Future evaluation will focus on assessing the overall concept and exploring which LLMs are best suited for the task. Developing strategies to reduce errors in SPARQL query gen- eration, especially for complex queries, is crucial for enhanc- ing accuracy and reliability. Improving user interaction with ontology-based systems by refining prompts and optimizing how the ontology context is provided to the language model is also important. Additionally, exploring the impact of detailed rdfs:comment on the quality of generated SPARQL queries is needed, including testing with more complex ontologies and varying the detail level of rdfs:comment. Implementing robust validation mechanisms is essential to ensure the accu- racy and trustworthiness of the generated queries, especially in industrial settings where incorrect information can have significant consequences. ACKNOWLEDGMENT This research [project ProMoDi and LaiLa] is funded by dtec.bw – Digitalization and Technology Research Center of the Bundeswehr. dtec.bw is funded by the European Union – NextGenerationEU. REFERENCES [1] C. Hildebrandt, A. K¨ocher, C. Kustner et al., “Ontology Building for Cyber–Physical Systems: Application in the Manufacturing Domain,” IEEE Transactions on Automation Science and Engineering, vol. 17, no. 3, pp. 1266–1282, 2020. [2] T. Jeleniewski, H. Nabizada, J. Reif et al., “A Semantic Model to Ex- press Process Parameters and their Interdependencies in Manufacturing,” in 2023 IEEE 32nd International Symposium on Industrial Electronics (ISIE). IEEE, 2023, pp. 1–6. [3] J. Reif, T. Jeleniewski, and A. Fay, “An Approach to Automating the Generation of Process Simulation Sequences,” in 2023 IEEE 28th Inter- national Conference on Emerging Technologies and Factory Automation (ETFA). IEEE, 2023, pp. 1–4. [4] M. S. Gill and A. Fay, “Utilisation of semantic technologies for the realisation of data-driven process improvements in the maintenance, repair and overhaul of aircraft components,” CEAS Aeronautical Journal, vol. 15, no. 2, pp. 459–480, 2023. [5] Y.-H. Chen, E. J.-L. Lu, and Y.-Y. Lin, “Efficient SPARQL Queries Generator for Question Answering Systems,” IEEE Access, vol. 10, pp. 99 850–99 860, 2022. [6] C. V. S. Avila, V. M. Vidal, W. Franco et al., “Experiments with text-to-SPARQL based on ChatGPT,” in 2024 IEEE 18th International Conference on Semantic Computing (ICSC). IEEE, 2024, pp. 277–284. [7] M. Yani and A. A. Krisnadhi, “Challenges, Techniques, and Trends of Simple Knowledge Graph Question Answering: A Survey,” Information, vol. 12, no. 7, p. 271, 2021. [8] J. Sai Sharath and R. Banafsheh, “Conversational Question Answering Over Knowledge Base using Chat-Bot Framework,” in 2021 IEEE 15th International Conference on Semantic Computing (ICSC). IEEE, 2021, pp. 84–85. [9] J. Martinez-Gil, S. Yin, J. K¨ung et al., “Knowledge Graph Augmentation for Increased Question Answering Accuracy,” in Transactions on large- scale data- and knowledge-centered systems LII, A. Hameurlain and A. M. Tjoa, Eds. Berlin: Springer, 2022, vol. 13470, pp. 70–85. [10] J. Chen, P. Hu, E. Jimenez-Ruiz et al., “OWL2Vec*: embedding of OWL ontologies,” Machine Learning, vol. 110, no. 7, pp. 1813–1845, 2021. [11] Y. Chen, E. J.-L. Lu, and Jin-De, Boosting Question Answering Systems with Multi-Label Classification Techniques, 2023. [12] VDI/VDE 3682:2, “Formalised Process Descriptions - Information Model,” 05.2015. [13] DIN EN 61360-1, “Standard data element types with associated clas- sification scheme - Part 1: Definitions - Principles and methods (IEC 61360-1:2017),” 07.2018. [14] VDI/VDE 2206, “Development of mechatronic and cyber-physical sys- tems,” 11.2021. [15] M. R. A. H. Rony, U. Kumar, R. Teucher et al., “SGPT: A Generative Approach for SPARQL Query Generation From Natural Language Questions,” IEEE Access, vol. 10, pp. 70 712–70 723, 2022.\n\n","libVersion":"0.5.0","langs":""}